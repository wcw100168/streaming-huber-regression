# ä¸²æµ Huber å›žæ­¸å¥—ä»¶ GitHub ç™¼å¸ƒèˆ‡ä½¿ç”¨æ•™å­¸

## ç›®éŒ„
1. [æº–å‚™å·¥ä½œ](#æº–å‚™å·¥ä½œ)
2. [ä¸Šå‚³å¥—ä»¶åˆ° GitHub](#ä¸Šå‚³å¥—ä»¶åˆ°-github)
3. [å¾ž GitHub å®‰è£ä½¿ç”¨å¥—ä»¶](#å¾ž-github-å®‰è£ä½¿ç”¨å¥—ä»¶)
4. [å¥—ä»¶ä½¿ç”¨æ•™å­¸](#å¥—ä»¶ä½¿ç”¨æ•™å­¸)
5. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

---

## æº–å‚™å·¥ä½œ

### 1. å®‰è£å¿…è¦å·¥å…·

ç¢ºä¿ä½ çš„é›»è…¦å·²å®‰è£ï¼š
- **Git**: [ä¸‹è¼‰ Git](https://git-scm.com/download)
- **GitHub å¸³è™Ÿ**: [è¨»å†Š GitHub](https://github.com)

### 2. é©—è­‰å®‰è£
```bash
# æª¢æŸ¥ Git æ˜¯å¦å®‰è£æˆåŠŸ
git --version

# è¨­å®š Git ç”¨æˆ¶è³‡è¨Šï¼ˆå¦‚æžœé‚„æ²’è¨­å®šï¼‰
git config --global user.name "ä½ çš„å§“å"
git config --global user.email "ä½ çš„ä¿¡ç®±@example.com"
```

---

## ä¸Šå‚³å¥—ä»¶åˆ° GitHub

### æ­¥é©Ÿ 1: å‰µå»º GitHub å„²å­˜åº«

1. ç™»å…¥ [GitHub](https://github.com)
2. é»žæ“Šå³ä¸Šè§’çš„ "+" â†’ "New repository"
3. å¡«å¯«å„²å­˜åº«è³‡è¨Šï¼š
   - **Repository name**: `streaming-huber-regression`
   - **Description**: `A Python package for streaming Huber regression with adaptive regularization`
   - **Public/Private**: é¸æ“‡ Publicï¼ˆè®“å…¶ä»–äººå¯ä»¥ä½¿ç”¨ï¼‰
   - âœ… å‹¾é¸ "Add a README file"
   - âœ… å‹¾é¸ "Add .gitignore" â†’ é¸æ“‡ "Python"
   - å¯é¸æ“‡ "Choose a license" â†’ å»ºè­°é¸æ“‡ "MIT License"
4. é»žæ“Š "Create repository"

### æ­¥é©Ÿ 2: åˆå§‹åŒ–æœ¬åœ° Git å„²å­˜åº«

åœ¨çµ‚ç«¯æ©Ÿä¸­åŸ·è¡Œï¼š

```bash
# é€²å…¥å¥—ä»¶ç›®éŒ„
cd "/Users/user/Downloads/å·¨é‡è³‡æ–™åˆ†æžæœŸæœ«/å¯¦ä½œå˜—è©¦v7/streaming_huber_regression"

# åˆå§‹åŒ– Git å„²å­˜åº«
git init

# æ·»åŠ é ç«¯å„²å­˜åº«ï¼ˆæ›¿æ›æˆä½ çš„ GitHub ç”¨æˆ¶åï¼‰
git remote add origin https://github.com/ä½ çš„ç”¨æˆ¶å/streaming-huber-regression.git
```

### æ­¥é©Ÿ 3: å‰µå»º .gitignore æª”æ¡ˆ

```bash
# å‰µå»º .gitignore æª”æ¡ˆ
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Testing
.pytest_cache/
.coverage
htmlcov/

# Jupyter Notebook
.ipynb_checkpoints

# Virtual Environment
venv/
env/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# macOS
.DS_Store

# Data files (å¯é¸ï¼Œå¦‚æžœä¸æƒ³ä¸Šå‚³å¤§åž‹è³‡æ–™æª”æ¡ˆ)
data/*.csv
*.csv
EOF
```

### æ­¥é©Ÿ 4: æ·»åŠ å’Œæäº¤æª”æ¡ˆ

```bash
# æ·»åŠ æ‰€æœ‰æª”æ¡ˆåˆ°æš«å­˜å€
git add .

# æäº¤æª”æ¡ˆ
git commit -m "Initial commit: Add streaming Huber regression package

- Core modules: trainer, standardizer, solvers
- Data loader with Dask support  
- Unit and integration tests
- Examples and documentation
- Complete package structure with setup.py"

# æŽ¨é€åˆ° GitHub
git push -u origin main
```

å¦‚æžœé‡åˆ°èªè­‰å•é¡Œï¼ŒGitHub ç¾åœ¨éœ€è¦ä½¿ç”¨ Personal Access Tokenï¼š

1. åˆ° GitHub â†’ Settings â†’ Developer settings â†’ Personal access tokens â†’ Tokens (classic)
2. é»žæ“Š "Generate new token (classic)"
3. å‹¾é¸ "repo" æ¬Šé™
4. è¤‡è£½ç”Ÿæˆçš„ token
5. åœ¨æŽ¨é€æ™‚ä½¿ç”¨ token ä½œç‚ºå¯†ç¢¼

### æ­¥é©Ÿ 5: å‰µå»ºç™¼å¸ƒç‰ˆæœ¬ï¼ˆå¯é¸ï¼‰

```bash
# å‰µå»ºæ¨™ç±¤
git tag -a v1.0.0 -m "Release version 1.0.0

Features:
- Streaming Huber regression with IRLS and LAMM solvers
- Online standardization with numerical stability
- Adaptive regularization with BIC model selection
- Memory-efficient data loading with Dask
- Comprehensive test suite
- Easy-to-use API with convenience functions"

# æŽ¨é€æ¨™ç±¤
git push origin v1.0.0
```

åœ¨ GitHub ç¶²é ä¸Šï¼š
1. åˆ°ä½ çš„å„²å­˜åº«é é¢
2. é»žæ“Š "Releases" â†’ "Create a new release"
3. é¸æ“‡å‰›å‰µå»ºçš„æ¨™ç±¤ `v1.0.0`
4. å¡«å¯«ç™¼å¸ƒèªªæ˜Ž
5. é»žæ“Š "Publish release"

---

## å¾ž GitHub å®‰è£ä½¿ç”¨å¥—ä»¶

### æ–¹æ³• 1: ç›´æŽ¥å¾ž GitHub å®‰è£ï¼ˆæŽ¨è–¦ï¼‰

```bash
# ä½¿ç”¨ pip ç›´æŽ¥å¾ž GitHub å®‰è£
pip install git+https://github.com/ä½ çš„ç”¨æˆ¶å/streaming-huber-regression.git

# æˆ–å®‰è£ç‰¹å®šç‰ˆæœ¬
pip install git+https://github.com/ä½ çš„ç”¨æˆ¶å/streaming-huber-regression.git@v1.0.0
```

### æ–¹æ³• 2: Clone å¾Œæœ¬åœ°å®‰è£

```bash
# Clone å„²å­˜åº«
git clone https://github.com/ä½ çš„ç”¨æˆ¶å/streaming-huber-regression.git

# é€²å…¥ç›®éŒ„
cd streaming-huber-regression

# å®‰è£ä¾è³´
pip install -r requirements.txt

# ä»¥é–‹ç™¼æ¨¡å¼å®‰è£å¥—ä»¶
pip install -e .
```

### æ–¹æ³• 3: ä¸‹è¼‰ä¸¦å®‰è£

```bash
# ä¸‹è¼‰ ZIP æª”æ¡ˆä¸¦è§£å£“å¾Œ
cd streaming-huber-regression-main

# å®‰è£
pip install .
```

---

## å¥—ä»¶ä½¿ç”¨æ•™å­¸

### å¿«é€Ÿé–‹å§‹

```python
# å°Žå…¥å¥—ä»¶
from streaming_huber import streaming_huber_training

# ä½¿ç”¨ä¾¿åˆ©å‡½æ•¸é€²è¡Œè¨“ç·´
result = streaming_huber_training(
    data_file_path="your_data.csv",  # ä½ çš„è³‡æ–™æª”æ¡ˆ
    max_samples=10000,               # è¨“ç·´æ¨£æœ¬æ•¸
    batch_size=1000,                 # æ‰¹æ¬¡å¤§å°
    n_batch=10,                      # æ‰¹æ¬¡æ•¸é‡
    tau_estimation_method='initial', # tau ä¼°è¨ˆæ–¹æ³•
    penalty=False                    # æ˜¯å¦ä½¿ç”¨æ­£å‰‡åŒ–
)

print(f"è¨“ç·´å®Œæˆï¼Œå¹³å‡ MAE: {result['avg_mae']:.4f}")
```

### è©³ç´°ä½¿ç”¨ç¯„ä¾‹

```python
import numpy as np
from streaming_huber import (
    StreamingDataLoaderWithDask,
    StreamingHuberModelTrainer,
    OnlineStandardizer
)

# 1. å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
loader = StreamingDataLoaderWithDask(
    file_path="data.csv",
    batch_size=500,
    max_samples=5000
)

# 2. å‰µå»ºè¨“ç·´å™¨
trainer = StreamingHuberModelTrainer(
    n_features=90,  # æ ¹æ“šä½ çš„è³‡æ–™ç‰¹å¾µæ•¸èª¿æ•´
    tau_estimation_method='initial',
    penalty=False,
    auto_lambda=True
)

# 3. æ‰¹æ¬¡è¨“ç·´
mae_history = []
for i, batch in enumerate(loader):
    if batch is None:
        break
    
    X, y = batch
    result = trainer.train_on_batch(X, y)
    mae = result.get('mae', 0)
    mae_history.append(mae)
    
    print(f"æ‰¹æ¬¡ {i+1}: MAE = {mae:.4f}")

# 4. é€²è¡Œé æ¸¬
test_loader = StreamingDataLoaderWithDask("test_data.csv", batch_size=1000)
test_batch = test_loader.get_batch()
if test_batch:
    X_test, y_test = test_batch
    predictions = trainer.predict(X_test)
    test_mae = np.mean(np.abs(predictions - y_test))
    print(f"æ¸¬è©¦ MAE: {test_mae:.4f}")

# 5. ä¿å­˜å’Œè¼‰å…¥æ¨¡åž‹
model_state = trainer.get_state()
# å¯ä»¥ä¿å­˜åˆ°æª”æ¡ˆ: np.save('model_state.npy', model_state)

# è¼‰å…¥æ¨¡åž‹
new_trainer = StreamingHuberModelTrainer(n_features=90)
new_trainer.set_state(model_state)
```

### é€²éšŽä½¿ç”¨ï¼šæ¯”è¼ƒä¸åŒé…ç½®

```python
from streaming_huber import streaming_huber_training

# æ¸¬è©¦ä¸åŒé…ç½®
configs = [
    {"penalty": False, "name": "ç„¡æ­£å‰‡åŒ–"},
    {"penalty": True, "auto_lambda": True, "name": "è‡ªå‹•æ­£å‰‡åŒ–"},
    {"penalty": True, "auto_lambda": False, "name": "å›ºå®šæ­£å‰‡åŒ–"}
]

results = {}
for config in configs:
    name = config.pop("name")
    result = streaming_huber_training(
        data_file_path="data.csv",
        max_samples=8000,
        batch_size=800,
        n_batch=10,
        **config
    )
    results[name] = result
    print(f"{name}: å¹³å‡ MAE = {result['avg_mae']:.4f}")

# æ‰¾å‡ºæœ€ä½³é…ç½®
best_config = min(results.items(), key=lambda x: x[1]['avg_mae'])
print(f"æœ€ä½³é…ç½®: {best_config[0]}")
```

---

## å¸¸è¦‹å•é¡Œ

### Q1: å®‰è£æ™‚å‡ºç¾æ¬Šé™éŒ¯èª¤
```bash
# ä½¿ç”¨ --user åƒæ•¸
pip install --user git+https://github.com/ä½ çš„ç”¨æˆ¶å/streaming-huber-regression.git

# æˆ–ä½¿ç”¨è™›æ“¬ç’°å¢ƒ
python -m venv streaming_huber_env
source streaming_huber_env/bin/activate  # Windows: streaming_huber_env\Scripts\activate
pip install git+https://github.com/ä½ çš„ç”¨æˆ¶å/streaming-huber-regression.git
```

### Q2: NumPy ç›¸å®¹æ€§è­¦å‘Š
```bash
# å¦‚æžœé‡åˆ° NumPy 2.x ç›¸å®¹æ€§å•é¡Œï¼Œå¯ä»¥é™ç´š
pip install "numpy<2.0"
pip install "pandas<2.0"
```

### Q3: è³‡æ–™æ ¼å¼è¦æ±‚
- CSV æª”æ¡ˆï¼Œç„¡æ¨™é¡Œè¡Œ
- ç¬¬ä¸€åˆ—ç‚ºç›®æ¨™è®Šæ•¸ï¼ˆyï¼‰
- å…¶é¤˜åˆ—ç‚ºç‰¹å¾µè®Šæ•¸ï¼ˆXï¼‰
- æ•¸å€¼è³‡æ–™ï¼Œç„¡ç¼ºå¤±å€¼

### Q4: è¨˜æ†¶é«”ä¸è¶³
```python
# æ¸›å°‘æ‰¹æ¬¡å¤§å°
loader = StreamingDataLoaderWithDask(
    file_path="data.csv",
    batch_size=100,  # é™ä½Žæ‰¹æ¬¡å¤§å°
    max_samples=1000
)
```

### Q5: æ›´æ–°å¥—ä»¶
```bash
# æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬
pip install --upgrade git+https://github.com/ä½ çš„ç”¨æˆ¶å/streaming-huber-regression.git
```

---

## æ¸¬è©¦å®‰è£

å‰µå»ºæ¸¬è©¦æª”æ¡ˆ `test_installation.py`ï¼š

```python
#!/usr/bin/env python3
"""æ¸¬è©¦å¥—ä»¶å®‰è£æ˜¯å¦æˆåŠŸ"""

import numpy as np

def test_import():
    """æ¸¬è©¦æ¨¡çµ„å°Žå…¥"""
    try:
        from streaming_huber import (
            StreamingHuberModelTrainer,
            StreamingDataLoaderWithDask,
            OnlineStandardizer,
            streaming_huber_training
        )
        print("âœ… æ¨¡çµ„å°Žå…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ æ¨¡çµ„å°Žå…¥å¤±æ•—: {e}")
        return False

def test_basic_functionality():
    """æ¸¬è©¦åŸºæœ¬åŠŸèƒ½"""
    try:
        from streaming_huber import OnlineStandardizer
        
        # æ¸¬è©¦æ¨™æº–åŒ–å™¨
        standardizer = OnlineStandardizer(n_features=3)
        X = np.random.randn(100, 3)
        standardizer.update(X)
        X_std = standardizer.transform(X)
        
        print(f"âœ… åŸºæœ¬åŠŸèƒ½æ¸¬è©¦é€šéŽ")
        print(f"   åŽŸå§‹è³‡æ–™å½¢ç‹€: {X.shape}")
        print(f"   æ¨™æº–åŒ–å¾Œå½¢ç‹€: {X_std.shape}")
        return True
    except Exception as e:
        print(f"âŒ åŸºæœ¬åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_synthetic_training():
    """æ¸¬è©¦åˆæˆè³‡æ–™è¨“ç·´"""
    try:
        from streaming_huber import StreamingHuberModelTrainer
        
        # ç”Ÿæˆåˆæˆè³‡æ–™
        np.random.seed(42)
        n_samples, n_features = 200, 5
        X = np.random.randn(n_samples, n_features)
        true_beta = np.random.randn(n_features)
        y = X @ true_beta + np.random.randn(n_samples) * 0.1
        
        # è¨“ç·´æ¨¡åž‹
        trainer = StreamingHuberModelTrainer(
            n_features=n_features,
            penalty=False
        )
        
        # æ‰¹æ¬¡è¨“ç·´
        batch_size = 50
        for i in range(0, n_samples, batch_size):
            end_idx = min(i + batch_size, n_samples)
            X_batch = X[i:end_idx]
            y_batch = y[i:end_idx]
            trainer.train_on_batch(X_batch, y_batch)
        
        # æ¸¬è©¦é æ¸¬
        predictions = trainer.predict(X[:50])
        mae = np.mean(np.abs(predictions - y[:50]))
        
        print(f"âœ… åˆæˆè³‡æ–™è¨“ç·´æ¸¬è©¦é€šéŽ")
        print(f"   è¨“ç·´æ¨£æœ¬æ•¸: {n_samples}")
        print(f"   ç‰¹å¾µç¶­åº¦: {n_features}")
        print(f"   æ¸¬è©¦ MAE: {mae:.4f}")
        return True
    except Exception as e:
        print(f"âŒ åˆæˆè³‡æ–™è¨“ç·´æ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("=" * 50)
    print("ä¸²æµ Huber å›žæ­¸å¥—ä»¶å®‰è£æ¸¬è©¦")
    print("=" * 50)
    
    tests = [
        test_import,
        test_basic_functionality,
        test_synthetic_training
    ]
    
    passed = 0
    for test in tests:
        if test():
            passed += 1
        print()
    
    print("=" * 50)
    print(f"æ¸¬è©¦çµæžœ: {passed}/{len(tests)} é€šéŽ")
    if passed == len(tests):
        print("ðŸŽ‰ å¥—ä»¶å®‰è£æˆåŠŸï¼Œå¯ä»¥é–‹å§‹ä½¿ç”¨ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥å®‰è£æˆ–ä¾è³´")
    print("=" * 50)
```

åŸ·è¡Œæ¸¬è©¦ï¼š
```bash
python test_installation.py
```

---

## å¥—ä»¶ç¶­è­·

### æ›´æ–°å¥—ä»¶
```bash
# é€²å…¥å¥—ä»¶ç›®éŒ„
cd streaming-huber-regression

# ä¿®æ”¹ç¨‹å¼ç¢¼å¾Œ
git add .
git commit -m "Update: æè¿°ä½ çš„æ›´æ”¹"
git push

# å‰µå»ºæ–°ç‰ˆæœ¬
git tag -a v1.0.1 -m "Bug fixes and improvements"
git push origin v1.0.1
```

### åˆ†æ”¯ç®¡ç†
```bash
# å‰µå»ºé–‹ç™¼åˆ†æ”¯
git checkout -b develop

# åˆä½µåˆ°ä¸»åˆ†æ”¯
git checkout main
git merge develop
git push
```

---

## ç¸½çµ

é€™ä»½æ•™å­¸æ¶µè“‹äº†ï¼š
1. âœ… **GitHub ä¸Šå‚³**: å¾žåˆå§‹åŒ–åˆ°ç™¼å¸ƒç‰ˆæœ¬
2. âœ… **å¥—ä»¶å®‰è£**: å¤šç¨®å®‰è£æ–¹å¼
3. âœ… **ä½¿ç”¨æ•™å­¸**: å¾žåŸºæœ¬åˆ°é€²éšŽä½¿ç”¨
4. âœ… **å•é¡Œè§£æ±º**: å¸¸è¦‹å•é¡Œå’Œè§£æ±ºæ–¹æ¡ˆ
5. âœ… **æ¸¬è©¦å·¥å…·**: é©—è­‰å®‰è£æ˜¯å¦æˆåŠŸ

ç¾åœ¨ä½ å¯ä»¥å°‡å¥—ä»¶åˆ†äº«çµ¦å…¶ä»–äººä½¿ç”¨ï¼Œæˆ–è€…åœ¨ä¸åŒçš„ç’°å¢ƒä¸­å®‰è£ä½¿ç”¨ä½ çš„ä¸²æµ Huber å›žæ­¸å¥—ä»¶ï¼

**è¨˜å¾—æ›¿æ›æ•™å­¸ä¸­çš„ `ä½ çš„ç”¨æˆ¶å` ç‚ºä½ å¯¦éš›çš„ GitHub ç”¨æˆ¶åã€‚**
